{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import subtitles_lines data from a pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./results/subtitles_lines.pkl', 'rb') as f:\n",
    "    subtitles_lines = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 2.86 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentences = []\n",
    "for subtitle_lines in subtitles_lines:\n",
    "    # first three sentences and the last one are not to be used\n",
    "    for line in subtitle_lines[3:-1]:\n",
    "        sentences.append(word_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112094"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "# from nltk.corpus import movie_reviews\n",
    "# sentences = [list(s) for s in movie_reviews.sents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.16 s, sys: 30.8 ms, total: 4.19 s\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Word2Vec(sentences, size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rachel', 0.8477544784545898),\n",
       " ('Joey', 0.8386672139167786),\n",
       " ('Chandler', 0.8252462148666382),\n",
       " ('Monica', 0.8095682263374329),\n",
       " ('Phoebe', 0.7773568034172058),\n",
       " ('Ben', 0.6479400396347046),\n",
       " ('Emma', 0.640067458152771),\n",
       " ('jumpy', 0.6378891468048096),\n",
       " ('everybody', 0.634537398815155),\n",
       " ('it', 0.6272266507148743)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['Ross', 'Emily'], negative=['Mark'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding distance between NE objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  I extracted only these two types because other types has no object.\n",
    "person_objects = None\n",
    "gpe_objects = None\n",
    "\n",
    "with open('./results/object_class.json', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        obj = json.loads(line)\n",
    "        if obj[\"title\"] == \"PERSON\":\n",
    "#             person_objects = json.loads(\"[\"+obj[\"objects\"]+\"]\")\n",
    "            person_objects = json.loads(obj[\"objects\"])\n",
    "        elif obj[\"title\"] == \"GPE\":\n",
    "#             gpe_objects = json.loads(\"[\"+obj[\"objects\"]+\"]\")\n",
    "            gpe_objects = json.loads(obj[\"objects\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for PERSON obejcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = [obj['title'] for obj in person_objects]\n",
    "gpes = [obj['title'] for obj in gpe_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "f = open('./results/person_object_relations.json', 'w')\n",
    "d = dict()\n",
    "d[\"id\"] = \"P1\"\n",
    "d[\"type\"] = \"relations\"\n",
    "d[\"title\"] = \"Embedding Distances Between PERSON objects\"\n",
    "d[\"objects\"] = []\n",
    "\n",
    "for i, a in enumerate(persons):\n",
    "    for j, b in enumerate(persons):\n",
    "        if i is not j:\n",
    "            d_ = dict()\n",
    "            d_[\"id\"] = \"R\" + str(idx)\n",
    "            d_[\"class\"] = \"P1\"\n",
    "            d_[\"type\"] = \"relation\"\n",
    "            d_[\"source\"] = \"O\" + str(i+1)\n",
    "            d_[\"target\"] = \"O\" + str(j+1)\n",
    "            d_[\"value\"] = model.wv.similarity(a, b)\n",
    "            d[\"objects\"].append(d_)\n",
    "            idx += 1\n",
    "\n",
    "f.write (json.dumps(d))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for GPE objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "f = open('./results/gpe_object_relations.json', 'w')\n",
    "d = dict()\n",
    "d[\"id\"] = \"P2\"\n",
    "d[\"type\"] = \"relations\"\n",
    "d[\"title\"] = \"Embedding Distances Between GPE objects\"\n",
    "d[\"objects\"] = []\n",
    "\n",
    "for i, a in enumerate(gpes):\n",
    "    for j, b in enumerate(gpes):\n",
    "        if i is not j:\n",
    "            d_ = dict()\n",
    "            d_[\"id\"] = \"R\" + str(idx)\n",
    "            d_[\"class\"] = \"P1\"\n",
    "            d_[\"type\"] = \"relation\"\n",
    "            d_[\"source\"] = \"O\" + str(i+1)\n",
    "            d_[\"target\"] = \"O\" + str(j+1)\n",
    "            d_[\"value\"] = model.wv.similarity(a, b)\n",
    "            d[\"objects\"].append(d_)\n",
    "            idx += 1\n",
    "\n",
    "f.write (json.dumps(d))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize word2vec vectors (option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(model.wv.vocab)\n",
    "X = model[vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_tsne, index=vocab, columns=['x', 'y'])\n",
    "df = df[:100]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(df['x'], df['y'])\n",
    "\n",
    "for word, pos in df.iterrows():\n",
    "    ax.annotate(word, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
